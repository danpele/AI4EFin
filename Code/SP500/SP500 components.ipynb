{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import datetime as dt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pickle \n",
    "import requests\n",
    "\n",
    "def save_sp500_tickers():\n",
    "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "    tickers = []\n",
    "    names = []\n",
    "    symbols=[[]]\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[0].text.replace('.', '-')\n",
    "        ticker = ticker[:-1]\n",
    "        tickers.append(ticker)\n",
    "        name = row.findAll('td')[1].text\n",
    "        name = name\n",
    "        names.append(name)\n",
    "\n",
    "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n",
    "        pickle.dump(symbols, f)\n",
    "    symbols=np.column_stack((tickers,names))\n",
    "    return symbols\n",
    "symbols=save_sp500_tickers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n",
      "[['MMM' '3M']\n",
      " ['AOS' 'A. O. Smith']\n",
      " ['ABT' 'Abbott']\n",
      " ...\n",
      " ['ZBH' 'Zimmer Biomet']\n",
      " ['ZION' 'Zions Bancorporation']\n",
      " ['ZTS' 'Zoetis']]\n"
     ]
    }
   ],
   "source": [
    "print(len(symbols))\n",
    "print(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already have MMM\n",
      "Already have AOS\n",
      "Already have ABT\n",
      "Already have ABBV\n",
      "Already have ACN\n",
      "Already have ADM\n",
      "Already have ADBE\n",
      "Already have ADP\n",
      "Already have AES\n",
      "Already have AFL\n",
      "Already have A\n",
      "Already have ABNB\n",
      "Already have APD\n",
      "Already have AKAM\n",
      "Already have ALK\n",
      "Already have ALB\n",
      "Already have ARE\n",
      "Already have ALGN\n",
      "Already have ALLE\n",
      "Already have LNT\n",
      "Already have ALL\n",
      "Already have GOOGL\n",
      "Already have GOOG\n",
      "Already have MO\n",
      "Already have AMZN\n",
      "Already have AMCR\n",
      "Already have AMD\n",
      "Already have AEE\n",
      "Already have AAL\n",
      "Already have AEP\n",
      "Already have AXP\n",
      "Already have AIG\n",
      "Already have AMT\n",
      "Already have AWK\n",
      "Already have AMP\n",
      "Already have AME\n",
      "Already have AMGN\n",
      "Already have APH\n",
      "Already have ADI\n",
      "Already have ANSS\n",
      "Already have AON\n",
      "Already have APA\n",
      "Already have AAPL\n",
      "Already have AMAT\n",
      "Already have APTV\n",
      "Already have ACGL\n",
      "Already have ANET\n",
      "Already have AJG\n",
      "Already have AIZ\n",
      "Already have T\n",
      "Already have ATO\n",
      "Already have ADSK\n",
      "Already have AZO\n",
      "Already have AVB\n",
      "Already have AVY\n",
      "Already have AXON\n",
      "Already have BKR\n",
      "Already have BALL\n",
      "Already have BAC\n",
      "Already have BBWI\n",
      "Already have BAX\n",
      "Already have BDX\n",
      "Already have WRB\n",
      "Already have BRK-B\n",
      "Already have BBY\n",
      "Already have BIO\n",
      "Already have TECH\n",
      "Already have BIIB\n",
      "Already have BLK\n",
      "Already have BX\n",
      "Already have BK\n",
      "Already have BA\n",
      "Already have BKNG\n",
      "Already have BWA\n",
      "Already have BXP\n",
      "Already have BSX\n",
      "Already have BMY\n",
      "Already have AVGO\n",
      "Already have BR\n",
      "Already have BRO\n",
      "Already have BF-B\n",
      "Already have BG\n",
      "Already have CHRW\n",
      "Already have CDNS\n",
      "Already have CZR\n",
      "Already have CPT\n",
      "Already have CPB\n",
      "Already have COF\n",
      "Already have CAH\n",
      "Already have KMX\n",
      "Already have CCL\n",
      "Already have CARR\n",
      "Already have CTLT\n",
      "Already have CAT\n",
      "Already have CBOE\n",
      "Already have CBRE\n",
      "Already have CDW\n",
      "Already have CE\n",
      "Already have COR\n",
      "Already have CNC\n",
      "Already have CNP\n",
      "Already have CDAY\n",
      "Already have CF\n",
      "Already have CRL\n",
      "Already have SCHW\n",
      "Already have CHTR\n",
      "Already have CVX\n",
      "Already have CMG\n",
      "Already have CB\n",
      "Already have CHD\n",
      "Already have CI\n",
      "Already have CINF\n",
      "Already have CTAS\n",
      "Already have CSCO\n",
      "Already have C\n",
      "Already have CFG\n",
      "Already have CLX\n",
      "Already have CME\n",
      "Already have CMS\n",
      "Already have KO\n",
      "Already have CTSH\n",
      "Already have CL\n",
      "Already have CMCSA\n",
      "Already have CMA\n",
      "Already have CAG\n",
      "Already have COP\n",
      "Already have ED\n",
      "Already have STZ\n",
      "Already have CEG\n",
      "Already have COO\n",
      "Already have CPRT\n",
      "Already have GLW\n",
      "Already have CTVA\n",
      "Already have CSGP\n",
      "Already have COST\n",
      "Already have CTRA\n",
      "Already have CCI\n",
      "Already have CSX\n",
      "Already have CMI\n",
      "Already have CVS\n",
      "Already have DHI\n",
      "Already have DHR\n",
      "Already have DRI\n",
      "Already have DVA\n",
      "Already have DE\n",
      "Already have DAL\n",
      "Already have XRAY\n",
      "Already have DVN\n",
      "Already have DXCM\n",
      "Already have FANG\n",
      "Already have DLR\n",
      "Already have DFS\n",
      "Already have DIS\n",
      "Already have DG\n",
      "Already have DLTR\n",
      "Already have D\n",
      "Already have DPZ\n",
      "Already have DOV\n",
      "Already have DOW\n",
      "Already have DTE\n",
      "Already have DUK\n",
      "Already have DD\n",
      "Already have EMN\n",
      "Already have ETN\n",
      "Already have EBAY\n",
      "Already have ECL\n",
      "Already have EIX\n",
      "Already have EW\n",
      "Already have EA\n",
      "Already have ELV\n",
      "Already have LLY\n",
      "Already have EMR\n",
      "Already have ENPH\n",
      "Already have ETR\n",
      "Already have EOG\n",
      "Already have EPAM\n",
      "Already have EQT\n",
      "Already have EFX\n",
      "Already have EQIX\n",
      "Already have EQR\n",
      "Already have ESS\n",
      "Already have EL\n",
      "Already have ETSY\n",
      "Already have EG\n",
      "Already have EVRG\n",
      "Already have ES\n",
      "Already have EXC\n",
      "Already have EXPE\n",
      "Already have EXPD\n",
      "Already have EXR\n",
      "Already have XOM\n",
      "Already have FFIV\n",
      "Already have FDS\n",
      "Already have FICO\n",
      "Already have FAST\n",
      "Already have FRT\n",
      "Already have FDX\n",
      "Already have FITB\n",
      "Already have FSLR\n",
      "Already have FE\n",
      "Already have FIS\n",
      "Already have FI\n",
      "Already have FLT\n",
      "Already have FMC\n",
      "Already have F\n",
      "Already have FTNT\n",
      "Already have FTV\n",
      "Already have FOXA\n",
      "Already have FOX\n",
      "Already have BEN\n",
      "Already have FCX\n",
      "Already have GRMN\n",
      "Already have IT\n",
      "Already have GEHC\n",
      "Already have GEN\n",
      "Already have GNRC\n",
      "Already have GD\n",
      "Already have GE\n",
      "Already have GIS\n",
      "Already have GM\n",
      "Already have GPC\n",
      "Already have GILD\n",
      "Already have GL\n",
      "Already have GPN\n",
      "Already have GS\n",
      "Already have HAL\n",
      "Already have HIG\n",
      "Already have HAS\n",
      "Already have HCA\n",
      "Already have PEAK\n",
      "Already have HSIC\n",
      "Already have HSY\n",
      "Already have HES\n",
      "Already have HPE\n",
      "Already have HLT\n",
      "Already have HOLX\n",
      "Already have HD\n",
      "Already have HON\n",
      "Already have HRL\n",
      "Already have HST\n",
      "Already have HWM\n",
      "Already have HPQ\n",
      "Already have HUM\n",
      "Already have HBAN\n",
      "Already have HII\n",
      "Already have IBM\n",
      "Already have IEX\n",
      "Already have IDXX\n",
      "Already have ITW\n",
      "Already have ILMN\n",
      "Already have INCY\n",
      "Already have IR\n",
      "Already have PODD\n",
      "Already have INTC\n",
      "Already have ICE\n",
      "Already have IFF\n",
      "Already have IP\n",
      "Already have IPG\n",
      "Already have INTU\n",
      "Already have ISRG\n",
      "Already have IVZ\n",
      "Already have INVH\n",
      "Already have IQV\n",
      "Already have IRM\n",
      "Already have JBHT\n",
      "Already have JKHY\n",
      "Already have J\n",
      "Already have JNJ\n",
      "Already have JCI\n",
      "Already have JPM\n",
      "Already have JNPR\n",
      "Already have K\n",
      "Already have KVUE\n",
      "Already have KDP\n",
      "Already have KEY\n",
      "Already have KEYS\n",
      "Already have KMB\n",
      "Already have KIM\n",
      "Already have KMI\n",
      "Already have KLAC\n",
      "Already have KHC\n",
      "Already have KR\n",
      "Already have LHX\n",
      "Already have LH\n",
      "Already have LRCX\n",
      "Already have LW\n",
      "Already have LVS\n",
      "Already have LDOS\n",
      "Already have LEN\n",
      "Already have LIN\n",
      "Already have LYV\n",
      "Already have LKQ\n",
      "Already have LMT\n",
      "Already have L\n",
      "Already have LOW\n",
      "Already have LYB\n",
      "Already have MTB\n",
      "Already have MRO\n",
      "Already have MPC\n",
      "Already have MKTX\n",
      "Already have MAR\n",
      "Already have MMC\n",
      "Already have MLM\n",
      "Already have MAS\n",
      "Already have MA\n",
      "Already have MTCH\n",
      "Already have MKC\n",
      "Already have MCD\n",
      "Already have MCK\n",
      "Already have MDT\n",
      "Already have MRK\n",
      "Already have META\n",
      "Already have MET\n",
      "Already have MTD\n",
      "Already have MGM\n",
      "Already have MCHP\n",
      "Already have MU\n",
      "Already have MSFT\n",
      "Already have MAA\n",
      "Already have MRNA\n",
      "Already have MHK\n",
      "Already have MOH\n",
      "Already have TAP\n",
      "Already have MDLZ\n",
      "Already have MPWR\n",
      "Already have MNST\n",
      "Already have MCO\n",
      "Already have MS\n",
      "Already have MOS\n",
      "Already have MSI\n",
      "Already have MSCI\n",
      "Already have NDAQ\n",
      "Already have NTAP\n",
      "Already have NFLX\n",
      "Already have NEM\n",
      "Already have NWSA\n",
      "Already have NWS\n",
      "Already have NEE\n",
      "Already have NKE\n",
      "Already have NI\n",
      "Already have NDSN\n",
      "Already have NSC\n",
      "Already have NTRS\n",
      "Already have NOC\n",
      "Already have NCLH\n",
      "Already have NRG\n",
      "Already have NUE\n",
      "Already have NVDA\n",
      "Already have NVR\n",
      "Already have NXPI\n",
      "Already have ORLY\n",
      "Already have OXY\n",
      "Already have ODFL\n",
      "Already have OMC\n",
      "Already have ON\n",
      "Already have OKE\n",
      "Already have ORCL\n",
      "Already have OGN\n",
      "Already have OTIS\n",
      "Already have PCAR\n",
      "Already have PKG\n",
      "Already have PANW\n",
      "Already have PARA\n",
      "Already have PH\n",
      "Already have PAYX\n",
      "Already have PAYC\n",
      "Already have PYPL\n",
      "Already have PNR\n",
      "Already have PEP\n",
      "Already have PFE\n",
      "Already have PCG\n",
      "Already have PM\n",
      "Already have PSX\n",
      "Already have PNW\n",
      "Already have PXD\n",
      "Already have PNC\n",
      "Already have POOL\n",
      "Already have PPG\n",
      "Already have PPL\n",
      "Already have PFG\n",
      "Already have PG\n",
      "Already have PGR\n",
      "Already have PLD\n",
      "Already have PRU\n",
      "Already have PEG\n",
      "Already have PTC\n",
      "Already have PSA\n",
      "Already have PHM\n",
      "Already have QRVO\n",
      "Already have PWR\n",
      "Already have QCOM\n",
      "Already have DGX\n",
      "Already have RL\n",
      "Already have RJF\n",
      "Already have RTX\n",
      "Already have O\n",
      "Already have REG\n",
      "Already have REGN\n",
      "Already have RF\n",
      "Already have RSG\n",
      "Already have RMD\n",
      "Already have RVTY\n",
      "Already have RHI\n",
      "Already have ROK\n",
      "Already have ROL\n",
      "Already have ROP\n",
      "Already have ROST\n",
      "Already have RCL\n",
      "Already have SPGI\n",
      "Already have CRM\n",
      "Already have SBAC\n",
      "Already have SLB\n",
      "Already have STX\n",
      "Already have SEE\n",
      "Already have SRE\n",
      "Already have NOW\n",
      "Already have SHW\n",
      "Already have SPG\n",
      "Already have SWKS\n",
      "Already have SJM\n",
      "Already have SNA\n",
      "Already have SEDG\n",
      "Already have SO\n",
      "Already have LUV\n",
      "Already have SWK\n",
      "Already have SBUX\n",
      "Already have STT\n",
      "Already have STLD\n",
      "Already have STE\n",
      "Already have SYK\n",
      "Already have SYF\n",
      "Already have SNPS\n",
      "Already have SYY\n",
      "Already have TMUS\n",
      "Already have TROW\n",
      "Already have TTWO\n",
      "Already have TPR\n",
      "Already have TRGP\n",
      "Already have TGT\n",
      "Already have TEL\n",
      "Already have TDY\n",
      "Already have TFX\n",
      "Already have TER\n",
      "Already have TSLA\n",
      "Already have TXN\n",
      "Already have TXT\n",
      "Already have TMO\n",
      "Already have TJX\n",
      "Already have TSCO\n",
      "Already have TT\n",
      "Already have TDG\n",
      "Already have TRV\n",
      "Already have TRMB\n",
      "Already have TFC\n",
      "Already have TYL\n",
      "Already have TSN\n",
      "Already have USB\n",
      "Already have UDR\n",
      "Already have ULTA\n",
      "Already have UNP\n",
      "Already have UAL\n",
      "Already have UPS\n",
      "Already have URI\n",
      "Already have UNH\n",
      "Already have UHS\n",
      "Already have VLO\n",
      "Already have VTR\n",
      "Already have VLTO\n",
      "Already have VRSN\n",
      "Already have VRSK\n",
      "Already have VZ\n",
      "Already have VRTX\n",
      "Already have VFC\n",
      "Already have VTRS\n",
      "Already have VICI\n",
      "Already have V\n",
      "Already have VMC\n",
      "Already have WAB\n",
      "Already have WBA\n",
      "Already have WMT\n",
      "Already have WBD\n",
      "Already have WM\n",
      "Already have WAT\n",
      "Already have WEC\n",
      "Already have WFC\n",
      "Already have WELL\n",
      "Already have WST\n",
      "Already have WDC\n",
      "Already have WRK\n",
      "Already have WY\n",
      "Already have WHR\n",
      "Already have WMB\n",
      "Already have WTW\n",
      "Already have GWW\n",
      "Already have WYNN\n",
      "Already have XEL\n",
      "Already have XYL\n",
      "Already have YUM\n",
      "Already have ZBRA\n",
      "Already have ZBH\n",
      "Already have ZION\n",
      "Already have ZTS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_data_from_yahoo(reload_sp500=True):\n",
    "    if reload_sp500:\n",
    "        symbols = save_sp500_tickers()\n",
    "    else:\n",
    "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "            symbols = pickle.load(f)\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start_date='2023-1-1'\n",
    "    end_date = '2023-6-30'\n",
    "    for i in range(len(symbols)):\n",
    "        ticker=symbols[i][0]\n",
    "\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "\n",
    "            tickerData = yf.Ticker(ticker)\n",
    "            df = tickerData.history(interval='1d', start=start_date, end=end_date)\n",
    "            df.reset_index(inplace=True)\n",
    "            df.set_index(\"Date\", inplace=True)\n",
    "            df['Name'] = symbols[i][1]\n",
    "            df['Symbol'] = symbols[i][0]\n",
    "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "\n",
    "\n",
    "get_data_from_yahoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Name</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03 00:00:00-05:00</th>\n",
       "      <td>116.395598</td>\n",
       "      <td>117.468371</td>\n",
       "      <td>115.294099</td>\n",
       "      <td>117.305542</td>\n",
       "      <td>2612800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 00:00:00-05:00</th>\n",
       "      <td>118.148422</td>\n",
       "      <td>120.006616</td>\n",
       "      <td>117.535411</td>\n",
       "      <td>119.872520</td>\n",
       "      <td>2769700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05 00:00:00-05:00</th>\n",
       "      <td>118.972160</td>\n",
       "      <td>119.316980</td>\n",
       "      <td>117.295956</td>\n",
       "      <td>117.774872</td>\n",
       "      <td>2606600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06 00:00:00-05:00</th>\n",
       "      <td>119.403191</td>\n",
       "      <td>121.769027</td>\n",
       "      <td>118.531561</td>\n",
       "      <td>121.376320</td>\n",
       "      <td>2417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09 00:00:00-05:00</th>\n",
       "      <td>121.644503</td>\n",
       "      <td>124.000773</td>\n",
       "      <td>120.792034</td>\n",
       "      <td>121.443359</td>\n",
       "      <td>2871300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-23 00:00:00-04:00</th>\n",
       "      <td>168.728928</td>\n",
       "      <td>169.307642</td>\n",
       "      <td>166.823116</td>\n",
       "      <td>168.000519</td>\n",
       "      <td>2412100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-26 00:00:00-04:00</th>\n",
       "      <td>167.541546</td>\n",
       "      <td>168.000529</td>\n",
       "      <td>164.188919</td>\n",
       "      <td>167.172348</td>\n",
       "      <td>1729200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27 00:00:00-04:00</th>\n",
       "      <td>168.429595</td>\n",
       "      <td>170.714563</td>\n",
       "      <td>166.783206</td>\n",
       "      <td>170.295486</td>\n",
       "      <td>1452300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 00:00:00-04:00</th>\n",
       "      <td>170.016090</td>\n",
       "      <td>170.425194</td>\n",
       "      <td>168.379690</td>\n",
       "      <td>168.728928</td>\n",
       "      <td>1686800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 00:00:00-04:00</th>\n",
       "      <td>168.279908</td>\n",
       "      <td>171.532764</td>\n",
       "      <td>167.830899</td>\n",
       "      <td>171.492844</td>\n",
       "      <td>1429000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60678 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2023-01-03 00:00:00-05:00  116.395598  117.468371  115.294099  117.305542   \n",
       "2023-01-04 00:00:00-05:00  118.148422  120.006616  117.535411  119.872520   \n",
       "2023-01-05 00:00:00-05:00  118.972160  119.316980  117.295956  117.774872   \n",
       "2023-01-06 00:00:00-05:00  119.403191  121.769027  118.531561  121.376320   \n",
       "2023-01-09 00:00:00-05:00  121.644503  124.000773  120.792034  121.443359   \n",
       "...                               ...         ...         ...         ...   \n",
       "2023-06-23 00:00:00-04:00  168.728928  169.307642  166.823116  168.000519   \n",
       "2023-06-26 00:00:00-04:00  167.541546  168.000529  164.188919  167.172348   \n",
       "2023-06-27 00:00:00-04:00  168.429595  170.714563  166.783206  170.295486   \n",
       "2023-06-28 00:00:00-04:00  170.016090  170.425194  168.379690  168.728928   \n",
       "2023-06-29 00:00:00-04:00  168.279908  171.532764  167.830899  171.492844   \n",
       "\n",
       "                            Volume  Dividends  Stock Splits    Name Symbol  \\\n",
       "Date                                                                         \n",
       "2023-01-03 00:00:00-05:00  2612800        0.0           0.0      3M    MMM   \n",
       "2023-01-04 00:00:00-05:00  2769700        0.0           0.0      3M    MMM   \n",
       "2023-01-05 00:00:00-05:00  2606600        0.0           0.0      3M    MMM   \n",
       "2023-01-06 00:00:00-05:00  2417000        0.0           0.0      3M    MMM   \n",
       "2023-01-09 00:00:00-05:00  2871300        0.0           0.0      3M    MMM   \n",
       "...                            ...        ...           ...     ...    ...   \n",
       "2023-06-23 00:00:00-04:00  2412100        0.0           0.0  Zoetis    ZTS   \n",
       "2023-06-26 00:00:00-04:00  1729200        0.0           0.0  Zoetis    ZTS   \n",
       "2023-06-27 00:00:00-04:00  1452300        0.0           0.0  Zoetis    ZTS   \n",
       "2023-06-28 00:00:00-04:00  1686800        0.0           0.0  Zoetis    ZTS   \n",
       "2023-06-29 00:00:00-04:00  1429000        0.0           0.0  Zoetis    ZTS   \n",
       "\n",
       "                          Adj Close  \n",
       "Date                                 \n",
       "2023-01-03 00:00:00-05:00       NaN  \n",
       "2023-01-04 00:00:00-05:00       NaN  \n",
       "2023-01-05 00:00:00-05:00       NaN  \n",
       "2023-01-06 00:00:00-05:00       NaN  \n",
       "2023-01-09 00:00:00-05:00       NaN  \n",
       "...                             ...  \n",
       "2023-06-23 00:00:00-04:00       NaN  \n",
       "2023-06-26 00:00:00-04:00       NaN  \n",
       "2023-06-27 00:00:00-04:00       NaN  \n",
       "2023-06-28 00:00:00-04:00       NaN  \n",
       "2023-06-29 00:00:00-04:00       NaN  \n",
       "\n",
       "[60678 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compile_data():\n",
    "    '''\n",
    "    with open(\"sp500tickers.pickle\", \"rb\") as f:\n",
    "        symbols= pickle.load(f)\n",
    "    '''\n",
    "    #symbols = save_sp500_tickers()\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(symbols)):\n",
    "        ticker=symbols[i][0]\n",
    "        df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        df.set_index('Date', inplace=True)\n",
    "       # df.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'],1,inplace=True)\n",
    "       \n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df=pd.concat([main_df,df])\n",
    "\n",
    "    return main_df\n",
    "\n",
    "compile_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=compile_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Name</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03 00:00:00-05:00</th>\n",
       "      <td>116.395598</td>\n",
       "      <td>117.468371</td>\n",
       "      <td>115.294099</td>\n",
       "      <td>117.305542</td>\n",
       "      <td>2612800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 00:00:00-05:00</th>\n",
       "      <td>118.148422</td>\n",
       "      <td>120.006616</td>\n",
       "      <td>117.535411</td>\n",
       "      <td>119.872520</td>\n",
       "      <td>2769700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05 00:00:00-05:00</th>\n",
       "      <td>118.972160</td>\n",
       "      <td>119.316980</td>\n",
       "      <td>117.295956</td>\n",
       "      <td>117.774872</td>\n",
       "      <td>2606600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06 00:00:00-05:00</th>\n",
       "      <td>119.403191</td>\n",
       "      <td>121.769027</td>\n",
       "      <td>118.531561</td>\n",
       "      <td>121.376320</td>\n",
       "      <td>2417000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09 00:00:00-05:00</th>\n",
       "      <td>121.644503</td>\n",
       "      <td>124.000773</td>\n",
       "      <td>120.792034</td>\n",
       "      <td>121.443359</td>\n",
       "      <td>2871300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2023-01-03 00:00:00-05:00  116.395598  117.468371  115.294099  117.305542   \n",
       "2023-01-04 00:00:00-05:00  118.148422  120.006616  117.535411  119.872520   \n",
       "2023-01-05 00:00:00-05:00  118.972160  119.316980  117.295956  117.774872   \n",
       "2023-01-06 00:00:00-05:00  119.403191  121.769027  118.531561  121.376320   \n",
       "2023-01-09 00:00:00-05:00  121.644503  124.000773  120.792034  121.443359   \n",
       "\n",
       "                            Volume  Dividends  Stock Splits Name Symbol  \\\n",
       "Date                                                                      \n",
       "2023-01-03 00:00:00-05:00  2612800        0.0           0.0   3M    MMM   \n",
       "2023-01-04 00:00:00-05:00  2769700        0.0           0.0   3M    MMM   \n",
       "2023-01-05 00:00:00-05:00  2606600        0.0           0.0   3M    MMM   \n",
       "2023-01-06 00:00:00-05:00  2417000        0.0           0.0   3M    MMM   \n",
       "2023-01-09 00:00:00-05:00  2871300        0.0           0.0   3M    MMM   \n",
       "\n",
       "                          Adj Close  \n",
       "Date                                 \n",
       "2023-01-03 00:00:00-05:00       NaN  \n",
       "2023-01-04 00:00:00-05:00       NaN  \n",
       "2023-01-05 00:00:00-05:00       NaN  \n",
       "2023-01-06 00:00:00-05:00       NaN  \n",
       "2023-01-09 00:00:00-05:00       NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-10-17'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver=dt.datetime.today().strftime('%Y-%m-%d')\n",
    "ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip',\n",
    "\n",
    "                        archive_name=str(ver)+'_SP500.csv')  \n",
    "\n",
    "main_df.to_csv(str(ver)+'_SP500.csv', index=False,\n",
    "\n",
    "          compression=compression_opts)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
